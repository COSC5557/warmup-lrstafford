\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{exercise1}
    
    
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{this-exercise-was-performed-on-arcc-beartooth-using-the-following-environmentsoftware-packages}{%
\paragraph{This exercise was performed on ARCC Beartooth\cite{beartooth} using the
following environment/software
packages:}\label{this-exercise-was-performed-on-arcc-beartooth-using-the-following-environmentsoftware-packages}}

Conda Env Exported to: lreilly-bt-ml.yml

\hypertarget{load-preinstalled-modules}{%
\paragraph{Load Preinstalled Modules:}\label{load-preinstalled-modules}}

module load gcc12.2.0 miniconda3 git/2.37.0

\hypertarget{create-environment-then-activate-with}{%
\paragraph{Create environment then activate
with:}\label{create-environment-then-activate-with}}

conda env create -f whatev\_ml\_env.yml\\
conda activate whatev\_ml\_env

\hypertarget{make-sure-jupyter-can-see-the-kernel-in-your-conda-env-so-you-can-select-from-southpass-interface-dropdown}{%
\paragraph{Make sure jupyter can see the kernel in your conda env so you
can select from southpass interface
dropdown:}\label{make-sure-jupyter-can-see-the-kernel-in-your-conda-env-so-you-can-select-from-southpass-interface-dropdown}}

python -m ipykernel install --user --name=whatev\_conda\_torch

\hypertarget{download-data-to-folder-and-extract}{%
\paragraph{Download data to folder and
extract}\label{download-data-to-folder-and-extract}}

wget https://archive.ics.uci.edu/static/public/186/wine+quality.zip\\
unzip wine+quality.zip


    \begin{Verbatim}[commandchars=\\\{\}]
Python Platform:macOS-14.0-arm64-arm-64bit
Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:41:52) [Clang
15.0.7 ]
PyTorch Version:  2.1.1
Pandas Version:  2.1.4
SkLearn Version:  1.3.0
    \end{Verbatim}



    \hypertarget{warmup}{%
\section{Warmup}\label{warmup}}

Download the
\href{https://archive.ics.uci.edu/dataset/186/wine+quality}{Wine Quality
dataset}. Choose the one that corresponds to your preference in wine.

Downloaded and unzipped to folder/repo

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Ensure we\PYZsq{}re looking at the right place}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{getcwd}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Import data and separate out}
\PY{n}{data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{winequality\PYZhy{}red.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{;}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}view data, get info about it, clean if necessary}
\PY{n}{data}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{p}{)}
\PY{n}{data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{T}
\end{Verbatim}
\end{tcolorbox}


            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                       count       mean        std      min      25\%  \textbackslash{}
fixed acidity         1599.0   8.319637   1.741096  4.60000   7.1000
volatile acidity      1599.0   0.527821   0.179060  0.12000   0.3900
citric acid           1599.0   0.270976   0.194801  0.00000   0.0900
residual sugar        1599.0   2.538806   1.409928  0.90000   1.9000
chlorides             1599.0   0.087467   0.047065  0.01200   0.0700
free sulfur dioxide   1599.0  15.874922  10.460157  1.00000   7.0000
total sulfur dioxide  1599.0  46.467792  32.895324  6.00000  22.0000
density               1599.0   0.996747   0.001887  0.99007   0.9956
pH                    1599.0   3.311113   0.154386  2.74000   3.2100
sulphates             1599.0   0.658149   0.169507  0.33000   0.5500
alcohol               1599.0  10.422983   1.065668  8.40000   9.5000
quality               1599.0   5.636023   0.807569  3.00000   5.0000

                           50\%        75\%        max
fixed acidity          7.90000   9.200000   15.90000
volatile acidity       0.52000   0.640000    1.58000
citric acid            0.26000   0.420000    1.00000
residual sugar         2.20000   2.600000   15.50000
chlorides              0.07900   0.090000    0.61100
free sulfur dioxide   14.00000  21.000000   72.00000
total sulfur dioxide  38.00000  62.000000  289.00000
density                0.99675   0.997835    1.00369
pH                     3.31000   3.400000    4.01000
sulphates              0.62000   0.730000    2.00000
alcohol               10.20000  11.100000   14.90000
quality                6.00000   6.000000    8.00000
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}


    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}data looks good, export and pull label data from rest of the dataset}
\PY{n}{labels} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{pop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{quality}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{display}\PY{p}{(}\PY{n}{labels}\PY{p}{)} \PY{c+c1}{\PYZsh{}should be a list of int64s}

\PY{c+c1}{\PYZsh{}Show a histogram of the distribution of label data}
\PY{n}{plot} \PY{o}{=} \PY{n}{labels}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hist}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Data Histogram}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_7_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{regression}{%
\subsection{Regression}\label{regression}}

Build a regression model to predict the wine quality. You can choose any
model type you like; the purpose of this exercise is to get you started.
Evaluate the performance of your trained model -- make sure to get an
unbiased performance estimate!

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}Initial Regression Model to Predict Wine Quality Using sklearn linear regression prepackaged ML}
\PY{c+c1}{\PYZsh{}https://scikit\PYZhy{}learn.org/stable/modules/generated/sklearn.linear\PYZus{}model.LinearRegression.html}

\PY{c+c1}{\PYZsh{}AKA\PYZsq{}ing our data into X features and y labels}
\PY{c+c1}{\PYZsh{}Uses train\PYZus{}test\PYZus{}split for model evals and use to shuffle our data and randomize what gets parsed to test and train}
\PY{n}{X\PYZus{}train\PYZus{}raw}\PY{p}{,} \PY{n}{X\PYZus{}test\PYZus{}raw}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{labels}\PY{p}{,} \PY{n}{train\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{.75}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\PY{n}{X\PYZus{}train\PYZus{}raw}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{X\PYZus{}test\PYZus{}raw}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
((1199, 11), (400, 11))
\end{Verbatim}
\end{tcolorbox}
        
  

    \begin{Verbatim}[commandchars=\\\{\}]
The Linear Regression Model Training Accuracy Score on is:  0.3632493675603261
The Linear Regression Model Explained Variance Score is:  0.3500683511219984
The Mean Squared Error for this Linear Regression Model is:  0.40007252708505525
the R2 Score for this Linear Regression Model is:  0.3454243812456276
    \end{Verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<Figure size 640x480 with 0 Axes>
    \end{Verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_10_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
The Linear Regression Model Explained Variance Score is:  0.25147508461923884
The Mean Sqared Error for this Linear Regression Model is:  0.4575
the R2 Score for this Linear Regression Model is:  0.251464858729331
    \end{Verbatim}


    \hypertarget{submission}{%
\subsection{Submission}\label{submission}}

Upload your code and a brief description of your results.

    \hypertarget{linear-regression-model-evaluation}{%
\subsubsection{Linear Regression Model
Evaluation:}\label{linear-regression-model-evaluation}}

This initial exercise uses the most basic of models (A Linear Regression
Model). It is recognized that this is far from an ideal model for this
particular prediction problem and dataset. The idea was to show a very
naively developed model, which should result in poor performance, and
then see how to improve upon it.

\hypertarget{metrics-used}{%
\subparagraph{Metrics Used:}\label{metrics-used}}

The Linear Regression Model Training Accuracy Score is:
0.5963302752293578 The Accuracy of the Test Data Predictions is: 0.6275
the R2 Score for this Logistic Regression Model is: 0.19829023120737088
For the Linear Regression Model, we use the following metrics for model
evaluation. 1. Model Prediction Score: Per
\href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\#sklearn.linear_model.LogisticRegression}{SciKitLearn's
Website}, The accuracy() method ``returns the mean accuracy on the given
data and labels.'' Additionally, when performing multi label
classification, ``this references the subset accuracy which is a harsh
metric since it requires each that each label set be correctly predicted
for each sample''. This particular score is used in this situation to
determine the accuracy of prediction on the training data.\\
2. Explained Variance Score: Per
\href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html\#sklearn.metrics.explained_variance_score}{SciKitLearn's
Website}, This metric essentially represents the amount of variation in
the original dataset that our model is able to explain. 3. MSE Score:
Per
\href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html\#sklearn.metrics.root_mean_squared_error}{SciKitLearn's
Website}, this calculates the mean squared error regression loss on the
model.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  R2 Score: Per
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\#sklearn.metrics.r2_score}{SciKitLearn's
  Website}, this returns the coefficient of determination on the
  regression model.
\end{enumerate}

\hypertarget{accuracy}{%
\subparagraph{Accuracy:}\label{accuracy}}

The above scores are all metrics to compute the accuracy of the overall
model. Run output is as follows:

Additionally, the linear regression model in general is very bad at
predicting lower quality wines. All predicted values tend to fall
between 5 and 7, and no values under quality 5 are ever predicted
correctly.

\hypertarget{summary}{%
\subparagraph{Summary:}\label{summary}}

The simple Linear Regression model is a classical model providing a line
for ordinary least squares linear regression on the dataset. The model
as developed is not a good predictor of wine quality and fails to
accurately predict true wine quality in a majority of cases on test
data.

\hypertarget{logistic-regression-model-evaluation}{%
\subsubsection{Logistic Regression Model
Evaluation}\label{logistic-regression-model-evaluation}}

This regression exercise uses a logistic regression model detailed
{[}here{]}
(https://scikit-learn.org/stable/modules/generated/sklearn.linear\_model.LogisticRegression.html).
This does a much better job of predicting values than the prior Linear
Model. Additionally, the logistic regression model uses the
{[}model\_selection.GridSearchCV() Optimizer{]}
(https://scikit-learn.org/stable/modules/generated/sklearn.model\_selection.GridSearchCV.html\#sklearn.model\_selection.GridSearchCV)
``to implement a fit and score method and apply them optimized by cross
validated grid-search over the parameter grid'' that is specified.
Ideally, this should come up with the best set of hyperparameters from
those listed in the parameter grid to optimize the model for Logistic
Regression. The specific hyperparameters are selected because they
support classification of multi-class datasets.

\hypertarget{metrics-used-1}{%
\subparagraph{Metrics Used:}\label{metrics-used-1}}

For the Logistic Regression Model, we use the following metrics for
model evaluation. 1. Model Prediction Score: Per
\href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\#sklearn.linear_model.LogisticRegression}{SciKitLearn's
Website}, The accuracy() method ``returns the mean accuracy on the given
data and labels.'' Additionally, when performing multi label
classification, ``this references the subset accuracy which is a harsh
metric since it requires each that each label set be correctly predicted
for each sample''.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Accuracy Score: Per
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\#sklearn.linear_model.LogisticRegression.score}{SciKitLearn's
  Website}, This metric represents the mean accuracy on the given test
  data and labels given the model as set.
\item
  MSE Score: Per
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html\#sklearn.metrics.root_mean_squared_error}{SciKitLearn's
  Website}, this calculates the mean squared error regression loss on
  the model.
\item
  R2 Score: Per
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\#sklearn.metrics.r2_score}{SciKitLearn's
  Website}, this returns the coefficient of determination on the
  regression model.
\end{enumerate}

\hypertarget{accuracy-1}{%
\subparagraph{Accuracy:}\label{accuracy-1}}

The above scores are all metrics to compute the accuracy of the overall
model. Run output is as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The Logistic Regression Model Training Accuracy Score is:
  0.5963302752293578
\item
  The Accuracy of the Test Data Predictions is: 0.6275
\item
  The R2 Score for this Logistic Regression Model is:
  0.19829023120737088
\item
  The Mean Squared Error for this model is: 0.49
\end{enumerate}

Evaluation metrics on this model are improved from the linear regression
model. It however, like the linear regression model does not do a great
job of predicting outliers. All predicted values tend to fall between 5
and 7.

\hypertarget{summary-1}{%
\subparagraph{Summary:}\label{summary-1}}

The Logistic Regression model performs a logistic regression using a
list of solvers then selected from optimized parameters within the
parameter grid. The model as developed is still not a good predictor of
wine quality and fails to accurately predict true wine quality in a
majority of cases on test data.

\hypertarget{classification-model-evaluation}{%
\subsubsection{Classification Model
Evaluation}\label{classification-model-evaluation}}

This particular classification model was designed using a classification
support vector machine (svc-SVM). Two different kernel selections were
made but other hyperparameters remain constant. Our kernel = linear in
our first run, and kernel = rbf (radial) in the second. In both
classification models, we set gamma = auto, and C = 5.

In the first case of classification a linear kernel is selected as it is
the most simple of kernel functions using a linear decision plane.

The second case of classification we selected a radial kernel (rbf).
This kernel requires C and gamma. C is our trade off value for
misclassifying. Giving C a lower value will make our decision surface
``softer'' while a higher value for C sets a higher value for
classifying our training examples correctly. Setting the value to 5 is
somewhat on the higher side, but not so rigid as to overfit our model to
the training data.

\hypertarget{metrics-used-2}{%
\subparagraph{Metrics Used:}\label{metrics-used-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Classification Score: Per
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\#sklearn.svm.SVC.score}{SciKitLearn's
  Website}, The score() method ``returns the mean accuracy of the model
  prediction on the given test data and labels''. Furthermore, ``In
  multilabel classification, this is the subset accuracy which is a
  harsh metric since it requires each label set be correctly predicted''
  (similar to the linear regression score function).
\item
  Accuracy Score: Per
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\#sklearn.metrics.accuracy_score}{SciKitLearn's
  Website}, This score metric ``returns the fraction of correctly
  classified samples''.
\item
  Confusion Matrix: Per
  \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\#sklearn.metrics.confusion_matrix}{SciKitLearn's
  Website}, The confusion matrix is used to evaluate the accuracy of our
  classification. The matrix shows true labels on on axis and predicted
  labels on the other axis, and provides a count for the number of
  predictions of each type vs what their true label type is.
\end{enumerate}

\hypertarget{accuracy-2}{%
\subparagraph{Accuracy:}\label{accuracy-2}}

Since we ran two separate SVC models with different kernels, we can
analyze the accuracy of each,

Linear Kernel

Beginning with the Linear Kernal, we can see that the model performs
alright. Certainly much better than our linear regression model.
Evaluation metric outputs are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The classification score for this Classification Model is:
  0.5796497080900751
\item
  The accuracy for this Classification Model is: 0.615
\end{enumerate}

On our first look, we can certainly see performance has improved with
the support vector machine compared to linear regression. Performance,
however is still not great. Under most circumstances, a ``good'' machine
learning model should perform with accuracy around 80\% or above.
Furthermore, our test dataset consists of a total of 400 wines. Of these
wines, the linear kernel classifies 131 wines of quality = 4 correctly,
and 115 wines of quality = 5 correctly. It however fails to classify any
wines correctly if they fall outside those labels and only predicts
their quality as either 4 or 5. 61 wines in the dataset have wine
quality falling outside the common quality labels 4 and 5 and all of
these wines are categorized incorrectly. Therefore the model performs
badly on all outliers.

Radial Kernel

In our second iteration of the SVC model, we use a radial kernel. This
model results with the following metrics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The classification score for this Classification Model is:
  0.8940783986655546
\item
  The accuracy for this Classification Model is: 0.55
\end{enumerate}

Our classification score is looks very high. Our total accuracy however
is lower than that of the linear kernel. The confusion matrix shows that
115 wines of quality 4 are predicted accurately, and 87 wines of quality
5 are predicted accurately. In addition, the radial model predicts 18
wines of quality 6 correctly. The radial model does appear to perform
better on outliers and does try to predcit outliers whereas the linear
model would not.

\hypertarget{summary-2}{%
\subparagraph{Summary:}\label{summary-2}}

The radial kernel performs well better on outlying data but we
compromise overall accuracy. The linear model performs with better
accuracy but fails on all outliers. In general the SVC performs far
better than a simple Linear Regression classifier.    


\begin{thebibliography}{9}
	\bibitem{Beartooth} Advanced Research Computing Center (2023) Beartooth Computing Environment, x86\_64 cluster. University of Wyoming, Laramie, WY https://doi.org/10.15786/M2FY47
	\bibitem{dataset1} A. Asuncion, D. Newman, UCI Machine Learning Repository, University of California, Irvine  (2007).  Obtained from https://archive-beta.ics.uci.edu/dataset/186/wine+quality. 
	\bibitem{numpyisnan} C. Harris, K. Millman, S. van der Walt,  Array programming with NumPy. Nature 585, 357â€“362 (2020). DOI: 10.1038/s41586-020-2649-2.  https://numpy.org/doc/stable/reference/generated/numpy.isnan.html
	\bibitem{scikitlearn}Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011. 
\end{thebibliography}

\end{document}