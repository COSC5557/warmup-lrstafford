{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609ba82d-b2fe-497b-82bc-c3a4b42f4556",
   "metadata": {},
   "source": [
    "# This exercise was performed on ARCC Beartooth with the following environment/software packages: \n",
    "\n",
    "# Load Preinstalled Modules\n",
    "module load gcc12.2.0 miniconda3 git/2.37.0\n",
    "\n",
    "# Create environment then activate with:\n",
    "conda env create -f whatev_ml_env.yml\n",
    "conda activate whatev_ml_env\n",
    "\n",
    "# Make sure jupyter can see the kernel in your conda env so you can select from southpass interface dropdown:\n",
    "python -m ipykernel install --user --name=whatev_conda_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa26f4b6-d6fb-4c34-8825-16fa10ffa544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "import torch as torch\n",
    "import os,sys,platform\n",
    "import torchvision as tv\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm #A progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ValidationCurveDisplay, GridSearchCV\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import ConfusionMatrixDisplay as showMatrix\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6eae2d-2ba4-485b-8f08-c6d2f3e1e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking devices available\n",
    "\n",
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "# Pretty-print the names\n",
    "for i in available_gpus:\n",
    "    print(torch.cuda.get_device_properties(i).name)\n",
    "\n",
    "# Prints 'Tesla V100-SXM2-16GB', for example\n",
    "print(torch.version.cuda)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91305df-b107-4dd8-9863-14c642b6c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm and checking platform and versions\n",
    "print(f\"Python Platform:{platform.platform()}\")\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"PyTorch Version: \", torch.__version__)\n",
    "print(f\"Pandas Version: \" , pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c994e2-83d0-4ada-82da-c7a7f59a1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data and separate out\n",
    "data = pd.read_csv('winequality-red.csv',sep=';')\n",
    "\n",
    "#view data, get info about it, clean if necessary\n",
    "data.info()\n",
    "data.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c577f2d-823d-485e-bdd1-9b1cd6ec6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data looks good, export and separate out labels\n",
    "labels = data.pop(\"quality\")\n",
    "display(labels) #should be a list of int64s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a009bb-5256-4a0b-bb58-d2af4d79da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a method that converts pandas dataframe to a pytorch tensor\n",
    "def to_tensor(df): return torch.tensor(df.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abf22a-a9c3-4bf6-b199-f55cf1c01ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AKA'ing our data into X features and y labels\n",
    "X,y = data,labels\n",
    "#Uses train_test_split for model evals and use to shuffle our data and randomize what gets parsed to test and train\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=.75, shuffle=True)\n",
    "\n",
    "#Standardizing our feature data vals to fall between 0 and 1\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "#Convert to 2D PyTorch Tensors now\n",
    "X_train=torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train=to_tensor(y_train).reshape(-1,1)\n",
    "X_test=torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test=to_tensor(y_test).reshape(-1,1)\n",
    "\n",
    "plot = labels.plot(kind='hist', title=\"Data Histogram\", figsize=(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598b87c-dfd7-4ae2-bf15-c3761b388a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define first iteration, model1 linear regression model initializer from pytorch's premade, prelearned nn linearRegression library.  Lazy - Booyah.  12 features go in, 1 label comes out.\n",
    "model1 = torch.nn.Linear(in_features=11,out_features=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91143fa2-4fd5-41aa-b915-4931b974988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making my own linear regression model2 from nn.Module from pytorch\n",
    "class myLinReg(torch.nn.Module):\n",
    "    #Constructor for initiating\n",
    "    def __init__(self, inputSz, outputSz):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(inputSz, outputSz)\n",
    "    #Define the forward function for predicting:\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc44e1-05af-4b71-bf4c-229f68b8e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some common training parameters I want to use for my Linear Regression model: model2\n",
    "n_epochs2 = 300\n",
    "batch_size=25\n",
    "learnRate=0.005\n",
    "#iterate one batch to next\n",
    "batch_start=torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "#hold my best model to use later\n",
    "best_mse2 = np.inf\n",
    "best_weights2 = None\n",
    "history2=[]\n",
    "\n",
    "\n",
    "#initialize my model!\n",
    "myLRmodel=myLinReg(11,1)\n",
    "\n",
    "#define criteria for the Loss Function with MSE (Mean Squared Error) to evaluate loss.\n",
    "lossfn2 = torch.nn.MSELoss()\n",
    "\n",
    "#define my optimizer function using optimizer from Stochastic Gradient Descent\n",
    "optimizer2 = torch.optim.SGD(myLRmodel.parameters(), learnRate)\n",
    "\n",
    "\n",
    "#Use GPU if we got it\n",
    "if device==\"cuda\":\n",
    "    myLRmodel.cuda()\n",
    "\n",
    "#Training my model - I'm honestly not sure if I need the if cuda/not or if that's \n",
    "#covered by what I just did with myRLmodel.cuda(). I usually just put it in in case.\n",
    "\n",
    "#loop through training\n",
    "for epoch in range (n_epochs2):\n",
    "    myLRmodel.train()\n",
    "    #Change inputs and labels to variables \n",
    "    if device==\"cuda\":\n",
    "        inputs = Variable(X_train).cuda()\n",
    "        labels = Variable(y_train).cuda()\n",
    "    else:\n",
    "        inputs = Variable(X_train)\n",
    "        labels = Variable(y_train)\n",
    "\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "        #takes a batch\n",
    "            X_batch = inputs[start:start+batch_size]\n",
    "            y_batch = labels[start:start+batch_size]\n",
    "\n",
    "            #forward pass\n",
    "            train_pred=myLRmodel(X_batch)\n",
    "            loss = lossfn2(train_pred, y_batch)\n",
    "\n",
    "            #backwards pass clearing optimizer gradient buffers so they don't accumulate\n",
    "            optimizer2.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #update weights\n",
    "            optimizer2.step()\n",
    "            \n",
    "            #print my progress (when in CLI)  Nothing to see here, folks.\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "        \n",
    "    #evaluate accuracy at end of each epoch against our test data\n",
    "    myLRmodel.eval()\n",
    "    test_pred = myLRmodel(X_test)\n",
    "    mse2 = lossfn2(test_pred, y_test)\n",
    "\n",
    "    #convert loss to a float val\n",
    "    mse2=float(mse2)\n",
    "\n",
    "    #save historic mse vals for comparison\n",
    "    history2.append(mse2)\n",
    "    if mse2 < best_mse2:\n",
    "        best_mse2=mse2\n",
    "        best_weights2 = myLRmodel.state_dict().copy()    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37129a3-96bf-4032-93f6-48e744899009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict X based on model1 from torch's prepacked LinearRegression model that's been scaled for between 0 and 1 to match mine.\n",
    "yPred1=model1(X_test)\n",
    "\n",
    "#print(\"Predictions for X using PyTorch LR Model: \", yPred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0412599-7988-4489-aa2c-157f6966235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring back my best stored model and return best accuracy\n",
    "myLRmodel.load_state_dict(best_weights2)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4524d544-58be-498c-b848-0c64966dcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear any previous plotting\n",
    "plt.clf()\n",
    "\n",
    "#Going to Plot the MSEs through each epoch\n",
    "print(\"MSE: \", \"%.2f\" % best_mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d8a29-e346-4060-aca6-b5fd2e3f81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2589eb9-d452-4537-bae9-ec96058c6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale train data and model predictions \n",
    "if device==\"cuda\":\n",
    "    train_pred = myLRmodel(Variable(X_train).cuda())\n",
    "else:\n",
    "    train_pred = myLRmodel(Variable(X_train))\n",
    "\n",
    "traintrue = y_train.squeeze().detach().numpy()\n",
    "trainpred = train_pred.squeeze().detach().numpy()\n",
    "\n",
    "print(len(trainpred))\n",
    "print(len(traintrue))\n",
    "\n",
    "\n",
    "train_error = r2(traintrue, trainpred, multioutput='raw_values')\n",
    "print(\"train metrics: \" , train_error)\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(traintrue, label=\"actual\")\n",
    "plt.plot(trainpred, label=\"predicted\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.ylim(0,10)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651f7a2-5d98-44e5-be86-b7022abfe099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do with test data now\n",
    "if device==\"cuda\":\n",
    "    test_pred = myLRmodel(Variable(X_test).cuda())\n",
    "else:\n",
    "    test_pred = myLRmodel(Variable(X_test))\n",
    "\n",
    "#print(train_pred)\n",
    "testtrue = y_test.squeeze().detach().numpy()\n",
    "testpred = test_pred.squeeze().detach().numpy()\n",
    "\n",
    "#print(testpred)\n",
    "\n",
    "test_error = r2(testtrue, testpred, multioutput='variance_weighted')\n",
    "print(\"test metrics: \", test_error)\n",
    "    \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(testtrue, label=\"actual\")\n",
    "plt.plot(testpred, label=\"predicted\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.ylim(0,10)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(torch.seed())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cb037-14b4-44c1-9b4f-923818998ff2",
   "metadata": {},
   "source": [
    "# This model is a sh__ show but with standard LR the way I'm doing it probably expected.\n",
    "\n",
    "# Lets do a VERY simple classification in scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155c58a-fd5d-401a-bbcd-5173a20d8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reget our data since we messed with it so much up above.\n",
    "#Import data and separate out\n",
    "data = pd.read_csv('winequality-red.csv',sep=';')\n",
    "labels = data.pop(\"quality\")\n",
    "\n",
    "#AKA'ing our data into X features and y labels\n",
    "#Uses train_test_split for model evals and use to shuffle our data and randomize what gets parsed to test and train\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(data, labels, train_size=.75, shuffle=True,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacdf5fa-e62e-47e9-a743-22eae6846635",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = svm.SVC(kernel=\"linear\", gamma='auto', C=5)\n",
    "classify.fit(X_train_raw, y_train)\n",
    "predictions = classify.predict(X_test_raw)\n",
    "\n",
    "print(predictions)\n",
    "flat_y = y_test.to_numpy()\n",
    "print(flat_y)\n",
    "print(classify.score(X_train, y_train))\n",
    "\n",
    "wineClassAccuracy = accuracy(y_test, predictions)\n",
    "print(wineClassAccuracy)\n",
    "\n",
    "\n",
    "wineClassConfMatrix = cm(y_test, predictions, labels=[1,2,3,4,5,6,7,8])\n",
    "disp=showMatrix(wineClassConfMatrix)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bfa008-7bc3-492a-8645-77c507d112ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(predictions, label = \"predicted\", linestyle=\"\")\n",
    "plt.plot(flat_y, label = \"actual\", linestyle=\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e12a903-7ee0-4d5c-807c-e05d2d8ae5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a chart of possible hyperparameters for SVM\n",
    "param={\n",
    "    'C':[.01, .1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [1,3,5,7,9],\n",
    "    'gamma': [0.01,0.1,1,10,100]\n",
    "}\n",
    "\n",
    "#make a quick and dirty helper to help us make a choice in terms of parameters \n",
    "#for our SVM with Scikitlearn tools\n",
    "def get_best_params(params):\n",
    "    svm  = SVC ();\n",
    "    svm_cv = GridSearchCV(svm, params, cv=3)\n",
    "    svm_cv.fit(X_train_raw, y_train)\n",
    "    print(\"Best Parameters are: \" , svm_cv.best_params_)\n",
    "    print(\"Best Training Score is: \" , svm_cv.best_score_)\n",
    "    print(\"Best Testing Score is: \", svm_cv.score(X_test_raw, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8308116-2e36-4b4d-87bd-ccc29d5be112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the function \n",
    "get_best_params(param)\n",
    "\n",
    "\n",
    "#This should print something out... not sure why it isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e100b-1685-4246-9b19-338c62f416ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-torch",
   "language": "python",
   "name": "conda-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
